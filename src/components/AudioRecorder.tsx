import { useState, useRef, useCallback, useEffect } from 'react';

interface AudioRecorderProps {
  onRecordingComplete?: (blob: Blob) => void;
  onRecordingStart?: () => void;
  onRecordingStop?: () => void;
  onVolumeChange?: (volume: number) => void;
  disabled?: boolean;
}

export default function AudioRecorder({ 
  onRecordingComplete,
  onRecordingStart,
  onRecordingStop,
  onVolumeChange,
  disabled = false
}: AudioRecorderProps) {
  const [isRecording, setIsRecording] = useState(false);
  const [volume, setVolume] = useState(0);
  const [recordingTime, setRecordingTime] = useState(0);
  
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const sourceRef = useRef<MediaStreamAudioSourceNode | null>(null);
  const animationFrameRef = useRef<number | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const timerRef = useRef<ReturnType<typeof setInterval> | null>(null);

  // æ¸…ç†èµ„æº
  const cleanup = useCallback(() => {
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }
    if (timerRef.current) {
      clearInterval(timerRef.current);
      timerRef.current = null;
    }
    if (sourceRef.current) {
      sourceRef.current.disconnect();
      sourceRef.current = null;
    }
    if (analyserRef.current) {
      analyserRef.current.disconnect();
      analyserRef.current = null;
    }
    if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }
    if (mediaRecorderRef.current) {
      mediaRecorderRef.current.stream.getTracks().forEach(track => track.stop());
      mediaRecorderRef.current = null;
    }
  }, []);

  useEffect(() => {
    return cleanup;
  }, [cleanup]);

  // å¼€å§‹å½•éŸ³
  const startRecording = useCallback(async () => {
    if (disabled) return;
    
    try {
      // è·å–éº¦å…‹é£æƒé™ - ä½¿ç”¨æ›´å…¼å®¹çš„é…ç½®
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: false,
          noiseSuppression: false,
          autoGainControl: false,
        }
      });
      
      // åˆ›å»º AudioContext - å…¼å®¹ iOS Safari
      const AudioContextClass = window.AudioContext || (window as unknown as { webkitAudioContext: typeof AudioContext }).webkitAudioContext;
      const audioContext = new AudioContextClass();
      audioContextRef.current = audioContext;
      
      // å¦‚æœæ˜¯ iOSï¼Œéœ€è¦æ¢å¤ AudioContext
      if (audioContext.state === 'suspended') {
        await audioContext.resume();
      }
      
      // åˆ›å»º AnalyserNode ç”¨äºéŸ³é‡å¯è§†åŒ–
      const analyser = audioContext.createAnalyser();
      analyser.fftSize = 256;
      analyserRef.current = analyser;
      
      // è¿æ¥éº¦å…‹é£åˆ° analyser
      const source = audioContext.createMediaStreamSource(stream);
      source.connect(analyser);
      sourceRef.current = source;
      
      // åˆ›å»º MediaRecorder - ä½¿ç”¨å…¼å®¹çš„ MIME ç±»å‹
      const mimeType = MediaRecorder.isTypeSupported('audio/webm') 
        ? 'audio/webm' 
        : MediaRecorder.isTypeSupported('audio/mp4') 
          ? 'audio/mp4' 
          : 'audio/ogg';
      
      const mediaRecorder = new MediaRecorder(stream, { mimeType });
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];
      
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };
      
      mediaRecorder.onstop = () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: mimeType });
        onRecordingComplete?.(audioBlob);
      };
      
      // å¼€å§‹å½•åˆ¶
      mediaRecorder.start(100); // æ¯ 100ms æ”¶é›†ä¸€æ¬¡æ•°æ®
      setIsRecording(true);
      setRecordingTime(0);
      onRecordingStart?.();
      
      // å¯åŠ¨è®¡æ—¶å™¨
      timerRef.current = setInterval(() => {
        setRecordingTime(prev => prev + 1);
      }, 1000);
      
      // å¯åŠ¨éŸ³é‡å¯è§†åŒ–
      const dataArray = new Uint8Array(analyser.frequencyBinCount);
      
      const updateVolume = () => {
        if (!analyserRef.current) return;
        
        analyserRef.current.getByteFrequencyData(dataArray);
        
        // è®¡ç®—å¹³å‡éŸ³é‡
        let sum = 0;
        for (let i = 0; i < dataArray.length; i++) {
          sum += dataArray[i];
        }
        const average = sum / dataArray.length;
        const normalizedVolume = Math.min(average / 128, 1); // å½’ä¸€åŒ–åˆ° 0-1
        
        setVolume(normalizedVolume);
        onVolumeChange?.(normalizedVolume);
        animationFrameRef.current = requestAnimationFrame(updateVolume);
      };
      
      updateVolume();
      
    } catch (error) {
      console.error('æ— æ³•è®¿é—®éº¦å…‹é£:', error);
      // æ›´å‹å¥½çš„é”™è¯¯æç¤º
      let errorMsg = 'æ— æ³•è®¿é—®éº¦å…‹é£';
      if (error instanceof DOMException) {
        if (error.name === 'NotAllowedError') {
          errorMsg = 'è¯·å…è®¸ä½¿ç”¨éº¦å…‹é£æƒé™';
        } else if (error.name === 'NotFoundError') {
          errorMsg = 'æœªæ‰¾åˆ°éº¦å…‹é£è®¾å¤‡';
        }
      }
      alert(errorMsg);
    }
  }, [disabled, onRecordingComplete, onRecordingStart, onVolumeChange]);

  // åœæ­¢å½•éŸ³
  const stopRecording = useCallback(() => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
      mediaRecorderRef.current.stop();
    }
    cleanup();
    setIsRecording(false);
    setVolume(0);
    onVolumeChange?.(0);
    onRecordingStop?.();
  }, [cleanup, onRecordingStop, onVolumeChange]);

  // æ ¼å¼åŒ–æ—¶é—´
  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
  };

  // è·å–éŸ³é‡æ¡é¢œè‰²
  const getVolumeColor = () => {
    if (volume < 0.3) return '#4ade80'; // ç»¿è‰² - ä½é¢‘
    if (volume < 0.6) return '#fbbf24'; // é»„è‰² - ä¸­é¢‘
    return '#3b82f6'; // è“è‰² - é«˜é¢‘
  };

  return (
    <div style={{
      ...styles.container,
      opacity: disabled ? 0.5 : 1,
      pointerEvents: disabled ? 'none' : 'auto',
    }}>
      {/* å½•éŸ³æ—¶é—´ */}
      <div style={styles.timeDisplay}>
        {formatTime(recordingTime)}
      </div>
      
      {/* éŸ³é‡å¯è§†åŒ– */}
      <div style={styles.visualizerContainer}>
        <div style={styles.volumeBars}>
          {Array.from({ length: 20 }).map((_, i) => {
            const threshold = (i + 1) / 20;
            const isActive = volume >= threshold;
            return (
              <div
                key={i}
                style={{
                  ...styles.volumeBar,
                  backgroundColor: isActive ? getVolumeColor() : '#374151',
                  height: `${Math.max(8, (i + 1) * 4)}px`,
                }}
              />
            );
          })}
        </div>
        <div style={styles.volumeText}>
          éŸ³é‡: {Math.round(volume * 100)}%
        </div>
      </div>
      
      {/* æ§åˆ¶æŒ‰é’® */}
      <div style={styles.controls}>
        {!isRecording ? (
          <button
            onClick={startRecording}
            style={{ ...styles.button, ...styles.startButton }}
          >
            <span style={styles.buttonIcon}>ğŸ¤</span>
            æŒ‰ä½å½•éŸ³
          </button>
        ) : (
          <button
            onClick={stopRecording}
            style={{ ...styles.button, ...styles.stopButton }}
          >
            <span style={styles.buttonIcon}>â¹</span>
            åœæ­¢å½•éŸ³
          </button>
        )}
      </div>
      
      {/* çŠ¶æ€æŒ‡ç¤º */}
      <div style={styles.status}>
        {isRecording ? (
          <span style={styles.recordingIndicator}>
            <span style={styles.recordingDot} /> æ­£åœ¨è†å¬ä½ çš„å£°éŸ³...
          </span>
        ) : (
          <span style={styles.idleStatus}>ç‚¹å‡»æŒ‰é’®å¼€å§‹å»ºé€ </span>
        )}
      </div>
    </div>
  );
}

const styles: Record<string, React.CSSProperties> = {
  container: {
    padding: '1.5rem',
    backgroundColor: '#1a1a2e',
    borderRadius: '12px',
    border: '1px solid #333355',
    transition: 'opacity 0.2s',
    touchAction: 'manipulation', // é˜²æ­¢åŒå‡»ç¼©æ”¾
    WebkitTapHighlightColor: 'transparent', // ç§»é™¤ç‚¹å‡»é«˜äº®
  },
  timeDisplay: {
    fontSize: 'clamp(1.75rem, 8vw, 2.5rem)', // å“åº”å¼å­—ä½“
    fontWeight: 'bold',
    color: '#fff',
    textAlign: 'center',
    fontFamily: 'monospace',
    marginBottom: '1rem',
    textShadow: '0 0 20px rgba(102, 126, 234, 0.5)',
  },
  visualizerContainer: {
    marginBottom: '1.25rem',
  },
  volumeBars: {
    display: 'flex',
    alignItems: 'flex-end',
    justifyContent: 'center',
    gap: 'clamp(2px, 1vw, 4px)', // å“åº”å¼é—´è·
    height: 'clamp(60px, 15vw, 80px)', // å“åº”å¼é«˜åº¦
    padding: '10px',
    backgroundColor: '#0a0a0f',
    borderRadius: '8px',
    border: '1px solid #222244',
  },
  volumeBar: {
    width: 'clamp(4px, 2vw, 8px)', // å“åº”å¼å®½åº¦
    borderRadius: '2px',
    transition: 'all 0.05s ease',
  },
  volumeText: {
    textAlign: 'center',
    color: '#8888aa',
    fontSize: 'clamp(0.75rem, 3vw, 0.875rem)', // å“åº”å¼å­—ä½“
    marginTop: '0.5rem',
  },
  controls: {
    display: 'flex',
    justifyContent: 'center',
    marginBottom: '1rem',
  },
  button: {
    display: 'flex',
    alignItems: 'center',
    justifyContent: 'center',
    gap: '8px',
    width: '100%',
    padding: 'clamp(0.875rem, 4vw, 1rem) clamp(1rem, 5vw, 1.5rem)', // å“åº”å¼å†…è¾¹è·
    fontSize: 'clamp(0.9rem, 4vw, 1rem)', // å“åº”å¼å­—ä½“
    fontWeight: '600',
    border: 'none',
    borderRadius: '8px',
    cursor: 'pointer',
    transition: 'all 0.2s ease',
    WebkitTouchCallout: 'none', // ç¦æ­¢é•¿æŒ‰èœå•
    userSelect: 'none',
  },
  startButton: {
    background: 'linear-gradient(135deg, #667eea 0%, #764ba2 100%)',
    color: 'white',
  },
  stopButton: {
    background: 'linear-gradient(135deg, #f87171 0%, #dc2626 100%)',
    color: 'white',
  },
  buttonIcon: {
    fontSize: 'clamp(1rem, 4vw, 1.2rem)',
  },
  status: {
    textAlign: 'center',
    fontSize: 'clamp(0.8rem, 3.5vw, 0.875rem)',
  },
  recordingIndicator: {
    display: 'inline-flex',
    alignItems: 'center',
    gap: '6px',
    color: '#f87171',
  },
  recordingDot: {
    width: '8px',
    height: '8px',
    backgroundColor: '#f87171',
    borderRadius: '50%',
    animation: 'pulse 1s infinite',
  },
  idleStatus: {
    color: '#666688',
  },
};
